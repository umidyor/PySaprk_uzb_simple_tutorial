{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIWwtkr7bEdowBb3s+2wT8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umidyor/PySaprk_uzb_simple_tutorial/blob/main/PySpark_dataframe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3qkaZhWmJNx",
        "outputId": "bd2d3d20-9765-45e9-ac23-ffd35bf17726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=b4414a1529dd25e57a22aebd0935492043537985aeda9b164a4969ac1bc3479b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark        #pyspark==3.4.1 -versiyasini yuklab oling\n",
        "#PySpark bilan Pandas orasidagi farq bu, pandas katta hajmga ega bo'lgan datalar ustida ishlashga qiynaladi.Shu sababli PySparkdan foydalanish qulay.PySpark bu Python+Java..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "dwggQFk8mPLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession   #SparkSession Spark bilan ishlash uchun PySpark da kiritiladigan asosiy obyekt hisoblanadi.\n",
        "#U SparkCluster bilan bog'lanishni o'rnatish, ma'lumotlar bazasiga so'rovlar yuborish, ma'lumotlarni ishlash va sair qo'llanmalarni o'z ichiga oladi..."
      ],
      "metadata": {
        "id": "U41kbZuxsbfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()  #pysparkdan foydalanish uchun muhit yaratamiz\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "XrjK4XL9sjH9",
        "outputId": "6bf2e544-8f1d-4edd-f457-c3559a6f2ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f957a4201f0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://58c5a9a94d58:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row     #Ushbu kutubxonadan foydalanib oddiygina spark dataframe yaratamiz.Row() funkisyasi bizga dataframe yaratishda avtomatik tarzda, ustunlarning datatype(turi)ni aniqab beradi\n",
        "spdf=spark.createDataFrame([\n",
        "    Row(yosh=15, yil=2007, Ism='Umidyor'),\n",
        "    Row(yosh=16, yil=2006, Ism='Atabek'),\n",
        "    Row(yosh=16, yil=2006, Ism=\"Shog'ulom\")\n",
        "])\n",
        "spdf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo9GDblqstSU",
        "outputId": "ab1d2cd5-34ac-43e9-8892-d291d4aa89fe"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+---------+\n",
            "|yosh| yil|      Ism|\n",
            "+----+----+---------+\n",
            "|  15|2007|  Umidyor|\n",
            "|  16|2006|   Atabek|\n",
            "|  16|2006|Shog'ulom|\n",
            "+----+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spdf.printSchema()   #ustunlar haqidagi ma'lumotlar.Ya'ni 'long' bu int bilan deyarli bir xil.Shunchaki int 32 bitli.'long' esa undan kattaroq."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvUb45nitmIt",
        "outputId": "0bfbda3a-667a-4c38-e62e-5c8aa9a21678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- yosh: long (nullable = true)\n",
            " |-- yil: long (nullable = true)\n",
            " |-- Ism: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spdf.show(1)   #1-qator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSFnl69qxVRy",
        "outputId": "ba9df591-b364-47aa-bdaf-c34c5e495a2d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+-------+\n",
            "|yosh| yil|    Ism|\n",
            "+----+----+-------+\n",
            "|  15|2007|Umidyor|\n",
            "+----+----+-------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spdf  #aamo bu yerda yosh ustuni bigint holda turbdi. bigint va long deyarli bir xil.Ikkalasi ham 64 bitlik butun sonlarni anglatadi\n"
      ],
      "metadata": {
        "id": "6t7muHaqxZnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d3a3d51-2f3d-4ca6-9b5f-44f0c111b5cd"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[yosh: bigint, yil: bigint, Ism: string]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, date                 #Ushbu holda shunchaki Row() funksiyasidan foydalanmasdan DataFrame yaratamiz.'schema' parametri orqali, biz ustunlarga nom beramiz va ularga mos datatypeni biriktiramiz!\n",
        "df = spark.createDataFrame([\n",
        "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
        "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
        "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
        "], schema='a bigint, b float, c string, d date, e timestamp')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAesyfNACnaq",
        "outputId": "012abc36-ea06-429e-a3a6-49104d045bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: float, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, date   #schema qo'syilishi shart emas\n",
        "df = spark.createDataFrame([\n",
        "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
        "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
        "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
        "], 'a bigint, b float, c string, d date, e timestamp')"
      ],
      "metadata": {
        "id": "5UN0T4D-NFJW"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEl7LetqElSj",
        "outputId": "ef065ec2-b54c-4b73-db57-fa662e56b974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
            "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_df = pd.DataFrame({                     #pandasdan foydalangan holda DataFrame yaratamiz va uni oson usulda spark dataframega o'giramiz.\n",
        "    'a': [1, 2, 3],\n",
        "    'b': [2., 3., 4.],\n",
        "    'c': ['string1', 'string2', 'string3'],\n",
        "    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n",
        "    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n",
        "})\n",
        "df = spark.createDataFrame(pandas_df)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcV99omJGYvc",
        "outputId": "cdd3eda2-151f-4b05-ceff-a4509b4dd68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ4UON7kGg-G",
        "outputId": "0fe5aed3-935c-40de-9296-7c12677d0bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
            "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbo1oXzZGjXw",
        "outputId": "8844cd27-0eda-4740-c2c2-6f5b83704b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
            "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n",
            "root\n",
            " |-- a: long (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- c: string (nullable = true)\n",
            " |-- d: date (nullable = true)\n",
            " |-- e: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"PySparkda foydalaniladigan bir nechta muhim ma'lumot turlarini va ularning tariflari:\n",
        "\n",
        "#Numeric Datatypes (Sonlar turlari):\n",
        "\n",
        "ByteType: 8-bit imzolangan butun son.\n",
        "ShortType: 16-bit imzolangan butun son.\n",
        "IntegerType: 32-bit imzolangan butun son.\n",
        "LongType: 64-bit imzolangan butun son.\n",
        "FloatType: 32-bit imzolanmagan o'lchamli son.\n",
        "DoubleType: 64-bit imzolanmagan o'lchamli son.\n",
        "Boolean Datatype (Mantiqiy turi):\n",
        "\n",
        "BooleanType: Mantiqiy qiymat (True yoki False).\n",
        "String Datatype (Matn turi):\n",
        "\n",
        "StringType: Matn qiymati.\n",
        "Binary Datatype (Binar turi):\n",
        "\n",
        "BinaryType: Binar qiymati.\n",
        "Date and Time Datatypes (Sana va vaqt turlari):\n",
        "\n",
        "DateType: Sana qiymati (YYYY-MM-DD).\n",
        "TimestampType: Vaqt qiymati (YYYY-MM-DD HH:MM:SS).\n",
        "Collection Datatypes (To'plam turlari):\n",
        "\n",
        "ArrayType: Elementlarining bir to'plamda joylashgan ro'yxati.\n",
        "MapType: Kalit-qiymat juftliklarining ro'yxati.\n",
        "StructType: Elementlarining nomlangan sifatlarini o'z ichiga olgan struktura.\"\"\""
      ],
      "metadata": {
        "id": "8Mmdjhd3JhSu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}